# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sxZBo58BxzmE4WoyoehWEB9qas1RU3Qd
"""

import os

if not os.path.exists('thinkdsp.py'):
    !wget https://github.com/AllenDowney/ThinkDSP/raw/master/code/thinkdsp.py

import numpy as np
import matplotlib.pyplot as plt
from thinkdsp import read_wave, Spectrum
from thinkdsp import decorate
from IPython.display import Audio

# Importuj biblioteki
import numpy as np
from scipy.fftpack import dct, idct
from scipy.io import wavfile

# Wczytaj sygnał audio
fs, audio_signal = wavfile.read('Thunder.wav')

# Rozdziel sygnał na fragmenty
fragment_length = 1024
num_fragments = int(len(audio_signal) / fragment_length)
audio_fragments = np.array_split(audio_signal, num_fragments)

# Wyznacz DCT dla każdego fragmentu
dct_fragments = []
for fragment in audio_fragments:
    dct_fragments.append(dct(fragment))

# Wybierz i usuń składowe częstotliwości o małych amplitudach
filtered_dct_fragments = []
for dct_fragment in dct_fragments:
    filtered_dct_fragment = dct_fragment.copy()
    for i in range(len(dct_fragment)):
        if np.any(abs(dct_fragment[i]) < 0.001):
            filtered_dct_fragment[i] = 0
    # Dopasuj wymiary wejściowe
    if filtered_dct_fragment.shape[0] < fragment_length:
        filtered_dct_fragment = np.pad(filtered_dct_fragment, (0, fragment_length - filtered_dct_fragment.shape[0]), 'constant', constant_values=0)
    filtered_dct_fragments.append(filtered_dct_fragment)

# Wyznacz odwrotną DCT i odtwórz sygnał
recovered_audio_signal = []
for filtered_dct_fragment in filtered_dct_fragments:
    recovered_audio_signal.append(idct(filtered_dct_fragment))

recovered_audio_signal = np.hstack(recovered_audio_signal)

# Zapisz odzyskany sygnał
wavfile.write('recovered_audio.wav', fs, recovered_audio_signal)

# podziel sygnał na fragmenty
signal = np.array("Thunder.wav") 
signal_segments = np.split(signal, 4)

# wyznacz DCT dla każdego z fragmentów
dct_signal_segments = []
for segment in signal_segments:
    dct_signal_segments.append(scipy.fftpack.dct(segment, norm='ortho'))

# określ i usuń składowe częstotliwości, które nie są słyszalne
frequencies = []
amplitudes = []
for dct_signal in dct_signal_segments:
    frequencies_segment, amplitudes_segment = find_frequencies_amplitudes(dct_signal)
    frequencies.append(frequencies_segment)
    amplitudes.append(amplitudes_segment)

# wyeliminuj składowe o małych amplitudach
frequencies_filtered, amplitudes_filtered = filter_low_amplitude(frequencies, amplitudes)

# odtwórz sygnał 
inverse_dct_signal_segments = []
for frequencies_segment, amplitudes_segment in zip(frequencies_filtered, amplitudes_filtered):
    inverse_dct_signal = inverse_dct(frequencies_segment, amplitudes_segment)
    inverse_dct_signal_segments.append(inverse_dct_signal)
    
# scal sygnały
inverse_dct_signal = np.concatenate(inverse_dct_signal_segments)

wave = read_wave("file.wav")
audio = Audio(data=wave.ys, rate=wave.framerate)
audio

compressed_signal = compress_signal(wave)